<!DOCTYPE html>
<html lang="en">
<head>

<!-- Primary Meta Tags -->
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Building a Knowledge Graph from Your AI Conversations - Kept</title>
<meta name="description" content="Your AI conversations are full of decisions, tools, people, and concepts buried in chat logs. A knowledge graph extracts and connects them across platforms and months of history.">
<meta name="keywords" content="AI conversation knowledge graph, knowledge graph AI chat, entity extraction AI conversations, NER AI conversations, build knowledge graph from text, AI conversation intelligence, cross-platform AI knowledge">
<link rel="canonical" href="https://kept.work/blog/building-knowledge-graph-ai-conversations/">
<meta name="robots" content="index, follow">
<meta name="author" content="Chris Hoar">
<meta name="theme-color" content="#09090b">
<link rel="icon" type="image/svg+xml" href="/KP5D/favicon.svg">

<!-- Open Graph -->
<meta property="og:title" content="Building a Knowledge Graph from Your AI Conversations">
<meta property="og:description" content="Your AI conversations contain structured intelligence. Decisions, tools, people, concepts. A knowledge graph extracts and connects them across every platform you use.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://kept.work/blog/building-knowledge-graph-ai-conversations/">
<meta property="og:image" content="https://kept.work/og-article-knowledge-graph.png">
<meta property="article:author" content="Chris Hoar">
<meta property="article:published_time" content="2026-04-10T00:00:00Z">
<meta property="article:section" content="Guide">
<meta property="article:tag" content="knowledge graph">
<meta property="article:tag" content="entity extraction">
<meta property="article:tag" content="AI conversations">
<meta property="article:tag" content="NER">

<!-- Twitter Card -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:title" content="Building a Knowledge Graph from Your AI Conversations">
<meta name="twitter:description" content="Your AI conversations contain structured intelligence. Decisions, tools, people, concepts. A knowledge graph extracts and connects them across every platform you use.">
<meta name="twitter:image" content="https://kept.work/og-article-knowledge-graph.png">

<!-- Article JSON-LD -->
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Building a Knowledge Graph from Your AI Conversations",
  "description": "Your AI conversations are full of decisions, tools, people, and concepts buried in chat logs. A knowledge graph extracts and connects them across platforms and months of history.",
  "author": {
    "@type": "Person",
    "name": "Chris Hoar"
  },
  "datePublished": "2026-04-10T00:00:00Z",
  "publisher": {
    "@type": "Organization",
    "name": "Kept",
    "url": "https://kept.work"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://kept.work/blog/building-knowledge-graph-ai-conversations/"
  },
  "keywords": "AI conversation knowledge graph, knowledge graph AI chat, entity extraction, NER, ChatGPT, Claude, Gemini, Kept",
  "wordCount": 2100
}
</script>

<!-- FAQ JSON-LD -->
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "FAQPage",
  "mainEntity": [
    {
      "@type": "Question",
      "name": "What is a knowledge graph in the context of AI conversations?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "A knowledge graph is a structured map of entities (people, tools, decisions, concepts) and their relationships, extracted from your AI conversation history. Instead of searching through raw chat logs, you query connected nodes."
      }
    },
    {
      "@type": "Question",
      "name": "Can I build a knowledge graph from ChatGPT conversations?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "Yes. Any conversation that contains decisions, tool evaluations, or referenced people can be parsed for entities. The challenge is doing this continuously across multiple platforms, which is what Kept automates."
      }
    },
    {
      "@type": "Question",
      "name": "How is this different from just searching my conversation history?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "Search finds keywords in text. A knowledge graph finds connections between concepts. Search answers 'where did I mention Redis?' A knowledge graph answers 'what decisions have I made that involve Redis, and how do they connect to my rate limiting and caching strategies?'"
      }
    },
    {
      "@type": "Question",
      "name": "Do I need to tag or organize my conversations manually?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "No. Entity extraction happens automatically using NER (Named Entity Recognition) and LLM-based parsing. The graph builds itself from your raw conversations."
      }
    },
    {
      "@type": "Question",
      "name": "Is my data sent to the cloud for knowledge graph extraction?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "Kept processes everything locally on your machine. Your conversations and the extracted knowledge graph stay on your device. Cloud LLM APIs are optional and configurable, with local inference via Ollama as a fully private alternative."
      }
    }
  ]
}
</script>

<!-- Fonts -->
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Instrument+Serif:ital@0;1&family=DM+Sans:ital,opsz,wght@0,9..40,300;0,9..40,400;0,9..40,500;0,9..40,600;1,9..40,300;1,9..40,400&family=IBM+Plex+Mono:wght@400;500&display=swap" rel="stylesheet">

<style>
:root {
  --c0: #09090b;
  --c1: #18181b;
  --c2: #3f3f46;
  --c3: #71717a;
  --c4: #a1a1aa;
  --c5: #e4e4e7;
  --c6: #f4f4f5;
  --cw: #fafafa;
  --white: #ffffff;
  --serif: 'Instrument Serif', Georgia, serif;
  --sans: 'DM Sans', system-ui, sans-serif;
  --mono: 'IBM Plex Mono', 'SF Mono', monospace;
  --s1: 4px; --s2: 8px; --s3: 12px; --s4: 16px; --s5: 20px;
  --s6: 24px; --s7: 32px; --s8: 40px; --s9: 48px; --s10: 64px;
  --s11: 80px; --s12: 120px;
  --r: 8px;
  --max: 1060px;
  --article: 720px;
}
* { margin: 0; padding: 0; box-sizing: border-box; }
html { font-size: 16px; scroll-behavior: smooth; -webkit-font-smoothing: antialiased; }
body { font-family: var(--sans); color: var(--c1); background: var(--white); line-height: 1.6; overflow-x: hidden; }
::selection { background: var(--c0); color: var(--white); }

.w { max-width: var(--max); margin: 0 auto; padding: 0 var(--s9); }
.wa { max-width: var(--article); margin: 0 auto; padding: 0 var(--s9); }
@media (max-width: 768px) { 
  .w { padding: 0 var(--s6); }
  .wa { padding: 0 var(--s6); }
}

nav { position: fixed; top: 0; left: 0; right: 0; z-index: 100; height: 56px; display: flex; align-items: center; background: rgba(255,255,255,0.85); backdrop-filter: blur(12px); -webkit-backdrop-filter: blur(12px); border-bottom: 1px solid var(--c5); }
nav .w { display: flex; align-items: center; justify-content: space-between; width: 100%; }
.nav-mark { font-family: var(--sans); font-weight: 600; font-size: 0.9rem; color: var(--c0); text-decoration: none; letter-spacing: -0.03em; }
.nav-r { display: flex; align-items: center; gap: var(--s7); }
.nav-r a { font-size: 0.82rem; color: var(--c3); text-decoration: none; transition: color 0.15s; }
.nav-r a:hover { color: var(--c0); }
.nav-r a.active { color: var(--c0); }

.btn { display: inline-flex; align-items: center; gap: var(--s2); font-family: var(--sans); font-size: 0.82rem; font-weight: 500; padding: var(--s2) var(--s4); border-radius: var(--r); text-decoration: none; transition: all 0.15s; letter-spacing: -0.01em; cursor: pointer; border: none; }
.btn-p { color: var(--white); background: var(--c0); }
.btn-p:hover { background: var(--c2); }

/* Article header */
.article-header { padding: 140px 0 var(--s8); }
.article-header-tag { font-family: var(--mono); font-size: 0.62rem; letter-spacing: 0.06em; text-transform: uppercase; color: var(--c4); margin-bottom: var(--s3); }
.article-header h1 { font-family: var(--serif); font-weight: 400; font-size: clamp(2rem, 4vw, 2.8rem); line-height: 1.15; letter-spacing: -0.03em; color: var(--c0); }
.article-subtitle { font-size: 1.1rem; color: var(--c3); margin-top: var(--s4); line-height: 1.4; }
.article-meta { display: flex; align-items: center; gap: var(--s2); margin-top: var(--s6); font-family: var(--mono); font-size: 0.72rem; color: var(--c3); }
.article-meta span { display: flex; align-items: center; }
.meta-sep { color: var(--c5); margin: 0 var(--s2); }

/* Article body */
.article-body { padding: 0 0 var(--s10); font-size: 1.05rem; line-height: 1.75; color: var(--c1); }
.article-body h2 { font-family: var(--serif); font-size: 1.75rem; font-weight: 400; line-height: 1.2; letter-spacing: -0.02em; color: var(--c0); margin: var(--s9) 0 var(--s5); }
.article-body h3 { font-family: var(--sans); font-size: 1.25rem; font-weight: 600; line-height: 1.3; color: var(--c0); margin: var(--s8) 0 var(--s4); }
.article-body p { margin-bottom: var(--s6); }
.article-body a { color: var(--c0); text-decoration: underline; text-underline-offset: 3px; text-decoration-thickness: 1px; transition: opacity 0.15s; }
.article-body a:hover { opacity: 0.7; }
.article-body ul, .article-body ol { margin: var(--s6) 0; padding-left: var(--s7); }
.article-body li { margin-bottom: var(--s3); }
.article-body strong { font-weight: 600; color: var(--c0); }
.article-body em { font-style: italic; }
.article-body code { font-family: var(--mono); font-size: 0.85em; background: var(--c6); padding: 2px 6px; border-radius: 4px; }
.article-body pre { background: var(--c6); padding: var(--s4); border-radius: var(--r); overflow-x: auto; margin: var(--s6) 0; }
.article-body pre code { background: transparent; padding: 0; }

/* Related articles */
.related { padding: var(--s10) 0; border-top: 1px solid var(--c5); }
.related h3 { font-family: var(--serif); font-size: 1.5rem; font-weight: 400; color: var(--c0); margin-bottom: var(--s7); }
.related-grid { display: grid; grid-template-columns: repeat(2, 1fr); gap: var(--s7); }
.related-item { text-decoration: none; }
.related-item:hover .related-title { color: var(--c2); }
.related-tag { font-family: var(--mono); font-size: 0.62rem; letter-spacing: 0.06em; text-transform: uppercase; color: var(--c4); margin-bottom: var(--s2); }
.related-title { font-family: var(--serif); font-size: 1.25rem; line-height: 1.3; color: var(--c0); margin-bottom: var(--s2); transition: color 0.15s; }
.related-excerpt { font-size: 0.88rem; line-height: 1.6; color: var(--c3); }

/* CTA */
.article-cta { text-align: center; padding: var(--s11) 0; border-top: 1px solid var(--c5); }
.article-cta h2 { font-family: var(--serif); font-size: clamp(1.8rem, 3vw, 2.4rem); font-weight: 400; line-height: 1.15; letter-spacing: -0.02em; color: var(--c0); margin-bottom: var(--s4); }
.article-cta p { font-size: 0.95rem; color: var(--c3); margin-bottom: var(--s7); }

footer { border-top: 1px solid var(--c5); padding: var(--s8) 0; display: flex; justify-content: space-between; align-items: center; }
.foot-l { font-family: var(--mono); font-size: 0.7rem; color: var(--c4); }
.foot-r { display: flex; gap: var(--s6); }
.foot-r a { font-size: 0.8rem; color: var(--c4); text-decoration: none; transition: color 0.15s; }
.foot-r a:hover { color: var(--c0); }

@media (max-width: 768px) {
  .article-header { padding-top: 120px; }
  .related-grid { grid-template-columns: 1fr; gap: var(--s8); }
  .nav-r a:not(.btn) { display: none; }
  footer { flex-direction: column; gap: var(--s6); text-align: center; }
}
</style>
</head>
<body>

<nav><div class="w">
  <a href="/KP5D/" class="nav-mark">Kept</a>
  <div class="nav-r">
    <a href="/KP5D/">Home</a>
    <a href="/KP5D/blog/" class="active">Blog</a>
    <a href="/KP5D/#go" class="btn btn-p">Join waitlist</a>
  </div>
</div></nav>

<article>
  <header class="article-header"><div class="wa">
    <p class="article-header-tag">Guide</p>
    <h1>Building a Knowledge Graph from Your AI Conversations</h1>
    <p class="article-subtitle">Your AI conversations contain decisions, tools, people, and concepts. A knowledge graph connects them across platforms and months of history. Here is how it works and why it matters.</p>
    <div class="article-meta">
      <span>Chris Hoar</span>
      <span class="meta-sep">•</span>
      <span>April 2026</span>
      <span class="meta-sep">•</span>
      <span>11 min read</span>
    </div>
  </div></header>

  <div class="article-body wa">
    <p>You had a conversation with Claude three weeks ago about choosing between Redis and Memcached for your caching layer. Last week you discussed rate limiting strategies with ChatGPT. Yesterday Gemini helped you evaluate API gateway options.</p>

    <p>All three conversations are connected. They are all part of the same architectural decision chain. But right now they exist as three isolated chat logs on three different platforms with no connections between them.</p>

    <p>This is the problem a knowledge graph solves. Not by organizing your conversations into folders. By extracting the entities, decisions, tools, and relationships buried inside them and connecting everything into a queryable structure.</p>

    <h2>What a knowledge graph actually is (skip the academic definition)</h2>

    <p>Nodes are things: people, tools, libraries, decisions, concepts. Edges are relationships: "chose X over Y," "referenced by," "decided on date," "mentioned by person." A knowledge graph is just a structured map of what you know, who was involved, what tools were discussed, and what decisions were made.</p>

    <p>Here's a simple example. From a single conversation about choosing Tauri over Electron, you can extract nodes for Tauri, Electron, Rust, bundle size, performance. Edges connect them: "Tauri chosen-over Electron," "Tauri built-with Rust," "decision motivated-by bundle size."</p>

    <p>That's it. No graph theory degree required. Just entities and how they relate to each other.</p>

    <h2>Why your AI conversations are perfect raw material</h2>

    <p>AI conversations are unusually rich sources for knowledge extraction because they are already semi-structured. You ask a question, the AI responds with organized information. Decisions get articulated with reasoning. Tools get compared with trade-offs listed. People get mentioned in context.</p>

    <p>Unlike meeting transcripts or Slack threads, AI conversations tend to be focused, topical, and information-dense. A 30-message conversation with Claude about your database architecture contains more extractable knowledge than a week of Slack messages.</p>

    <p>The problem is that this knowledge evaporates after the conversation ends. You remember the conclusion but forget the reasoning. You remember you chose PostgreSQL but not the five alternatives you evaluated or why you rejected them.</p>

    <h2>The four types of entities hiding in your conversations</h2>

    <p><strong>1. Decisions (with rationale and timestamps)</strong></p>
    
    <p>"Chose Tauri over Electron for desktop shell. Reasons: 5MB vs 150MB binary, Rust backend, native webview." These are the most valuable because decisions without recorded rationale get revisited and re-debated endlessly.</p>

    <p><strong>2. Tools and technologies</strong></p>
    
    <p>Every library, framework, service, and API you have discussed, evaluated, or decided to use. Not just what you chose but what you considered and rejected. Your conversation history is a complete technology radar that you never documented.</p>

    <p><strong>3. People</strong></p>
    
    <p>Team members, stakeholders, experts referenced in conversations. "Antal's feedback on the timeline" or "the approach Sarah recommended" become traceable references instead of vague memories.</p>

    <p><strong>4. Concepts and patterns</strong></p>
    
    <p>Architectural patterns, design principles, domain concepts that span multiple conversations. Federated learning, event sourcing, zero-trust architecture. These are the connective tissue between conversations.</p>

    <h2>How entity extraction actually works</h2>

    <p>Traditional NER (Named Entity Recognition) uses trained models to identify and classify entities in text. Modern approaches use LLMs themselves to extract entities because they understand context better than pattern-matching systems.</p>

    <p>For AI conversations specifically, the extraction pipeline looks like this:</p>

    <ul>
      <li>Parse the conversation into turns</li>
      <li>Run NER on each turn to identify entities</li>
      <li>Classify each entity (decision, tool, person, concept)</li>
      <li>Extract relationships between entities</li>
      <li>Resolve duplicates (is "Postgres" the same as "PostgreSQL"?)</li>
      <li>Add everything to the graph with timestamps and source references</li>
    </ul>

    <p>The challenge is entity resolution. "React" mentioned in a frontend conversation is React the UI library. "React" mentioned in a chemistry conversation is something else entirely. Context-aware extraction is what separates useful knowledge graphs from noisy ones.</p>

    <h2>Cross-conversation connections are where the real value lives</h2>

    <p>A knowledge graph from a single conversation is mildly useful. A knowledge graph that spans hundreds of conversations across multiple platforms over months of work is transformative.</p>

    <p>Example: you discussed Redis caching in ChatGPT in January. In March, you explored rate limiting in Claude and mentioned Redis again. In April, you evaluated API gateways in Gemini and the rate limiting decision came up.</p>

    <p>A cross-conversation knowledge graph connects all three automatically. You can ask: "What decisions have I made that involve Redis?" and get a complete timeline spanning three platforms and four months.</p>

    <p>No single AI platform can do this. ChatGPT does not know about your Claude conversations. Claude does not know about your Gemini chats. The knowledge graph is the layer that unifies everything.</p>

    <h2>What you can actually do with a conversation knowledge graph</h2>

    <p><strong>Decision archaeology:</strong> Trace back why you chose a particular approach months later, with full reasoning preserved. Every decision links back to the conversation where it was made.</p>

    <p><strong>Technology radar:</strong> See every tool and library you have evaluated, adopted, or rejected across all platforms. Discover patterns in what you consistently choose or avoid.</p>

    <p><strong>Pattern detection:</strong> Discover that you keep revisiting the same architectural question, which means you have not actually resolved it. The graph reveals when you're stuck in a decision loop.</p>

    <p><strong>Onboarding context:</strong> Share your knowledge graph with a new team member so they understand the project's decision history. They can explore the "why" behind every technical choice.</p>

    <p><strong>Weekly digests:</strong> Automated summaries of entities, decisions, and concepts from the past week. See what you've been thinking about across all platforms at a glance.</p>

    <h2>Building this yourself vs. using a tool</h2>

    <p>Let's be honest about the DIY approach. You could export your conversations, run them through an NER pipeline, and build a graph database. The open-source tooling exists: spaCy for NER, Neo4j for the graph, LangChain for LLM-based extraction.</p>

    <p>But the ongoing work of capture, extraction, resolution, and maintenance across multiple platforms is the hard part. It is not a weekend project. It is an ongoing pipeline.</p>

    <p>Here's what you'd need to build:</p>

    <pre><code>1. Chrome extensions for each platform
2. Export and normalization pipelines
3. Entity extraction with context awareness
4. Duplicate resolution across platforms
5. Graph database setup and maintenance
6. Query interface for exploring the graph
7. Continuous sync as new conversations happen</code></pre>

    <p>Kept approaches this differently. Because the Chrome extension captures conversations automatically and the desktop app indexes everything locally, the knowledge graph extraction runs continuously on your full archive.</p>

    <p>Entities, decisions, and relationships get extracted and connected as new conversations happen. The graph grows with every conversation you have, across every platform you use.</p>

    <p>If you want to see what a knowledge graph built from your own AI conversations looks like, Kept is launching in beta at kept.work. The capture and search layer is free and open source. The knowledge graph extraction is part of Kept Pro.</p>

    <h2>Frequently Asked Questions</h2>

    <h3>What is a knowledge graph in the context of AI conversations?</h3>
    <p>A knowledge graph is a structured map of entities (people, tools, decisions, concepts) and their relationships, extracted from your AI conversation history. Instead of searching through raw chat logs, you query connected nodes.</p>

    <h3>Can I build a knowledge graph from ChatGPT conversations?</h3>
    <p>Yes. Any conversation that contains decisions, tool evaluations, or referenced people can be parsed for entities. The challenge is doing this continuously across multiple platforms, which is what Kept automates.</p>

    <h3>How is this different from just searching my conversation history?</h3>
    <p>Search finds keywords in text. A knowledge graph finds connections between concepts. Search answers "where did I mention Redis?" A knowledge graph answers "what decisions have I made that involve Redis, and how do they connect to my rate limiting and caching strategies?"</p>

    <h3>Do I need to tag or organize my conversations manually?</h3>
    <p>No. Entity extraction happens automatically using NER (Named Entity Recognition) and LLM-based parsing. The graph builds itself from your raw conversations.</p>

    <h3>Is my data sent to the cloud for knowledge graph extraction?</h3>
    <p>Kept processes everything locally on your machine. Your conversations and the extracted knowledge graph stay on your device. Cloud LLM APIs are optional and configurable, with local inference via Ollama as a fully private alternative.</p>
  </div>
</article>

<section class="article-cta"><div class="wa">
  <h2>Your knowledge is trapped in chat logs</h2>
  <p>Kept extracts it into a queryable graph that spans every AI platform you use. Decisions, tools, people, concepts, all connected and searchable.</p>
  <a href="/KP5D/#go" class="btn btn-p">Join the beta</a>
</div></section>

<section class="related"><div class="wa">
  <h3>Related articles</h3>
  <div class="related-grid">
    <a href="/KP5D/blog/why-ai-platforms-will-never-index-each-other/" class="related-item">
      <p class="related-tag">Thought Leadership</p>
      <h4 class="related-title">Why AI Platforms Will Never Index Each Other</h4>
      <p class="related-excerpt">ChatGPT will never search your Claude conversations. This structural gap is permanent and widens with every new AI platform.</p>
    </a>
    <a href="/KP5D/blog/your-ai-conversations-are-a-codebase/" class="related-item">
      <p class="related-tag">Thought Leadership</p>
      <h4 class="related-title">Your AI Conversations Are a Codebase</h4>
      <p class="related-excerpt">You version control your code. You review your pull requests. But the AI conversations that shaped your architecture? Those disappear.</p>
    </a>
    <a href="/KP5D/blog/context-drift-killing-ai-coding-sessions/" class="related-item">
      <p class="related-tag">Guide</p>
      <h4 class="related-title">Context Drift Is Killing Your AI Coding Sessions</h4>
      <p class="related-excerpt">The longer your AI conversation runs, the worse the responses get. Context drift is measurable, predictable, and fixable.</p>
    </a>
  </div>
</div></section>

<div class="w"><footer>
  <span class="foot-l">Kept — An E-Group Labs product — 2026</span>
  <div class="foot-r"><a href="#">GitHub</a><a href="#">Docs</a><a href="#">Privacy</a></div>
</footer></div>

</body>
</html>